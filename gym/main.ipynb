{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1000 completed, episode length = 200\n",
      "Episode 2000 completed, episode length = 200\n",
      "Episode 3000 completed, episode length = 200\n",
      "Episode 4000 completed, episode length = 200\n",
      "Episode 5000 completed, episode length = 129\n",
      "Episode 6000 completed, episode length = 200\n",
      "Episode 7000 completed, episode length = 187\n",
      "Episode 8000 completed, episode length = 193\n",
      "Episode 9000 completed, episode length = 200\n",
      "Episode 10000 completed, episode length = 200\n",
      "Episode 11000 completed, episode length = 200\n",
      "Episode 12000 completed, episode length = 200\n",
      "Episode 13000 completed, episode length = 200\n",
      "Episode 14000 completed, episode length = 200\n",
      "Episode 15000 completed, episode length = 200\n",
      "Episode 16000 completed, episode length = 116\n",
      "Episode 17000 completed, episode length = 200\n",
      "Episode 18000 completed, episode length = 200\n",
      "Episode 19000 completed, episode length = 200\n",
      "Episode 20000 completed, episode length = 133\n",
      "Episode 21000 completed, episode length = 137\n",
      "Episode 22000 completed, episode length = 200\n",
      "Episode 23000 completed, episode length = 109\n",
      "Episode 24000 completed, episode length = 189\n",
      "Episode 25000 completed, episode length = 200\n",
      "Episode 26000 completed, episode length = 200\n",
      "Episode 27000 completed, episode length = 165\n",
      "Episode 28000 completed, episode length = 200\n",
      "Episode 29000 completed, episode length = 200\n",
      "Episode 30000 completed, episode length = 182\n",
      "Episode 31000 completed, episode length = 151\n",
      "Episode 32000 completed, episode length = 134\n",
      "Episode 33000 completed, episode length = 200\n",
      "Episode 34000 completed, episode length = 151\n",
      "Episode 35000 completed, episode length = 118\n",
      "Episode 36000 completed, episode length = 103\n",
      "Episode 37000 completed, episode length = 118\n",
      "Episode 38000 completed, episode length = 102\n",
      "Episode 39000 completed, episode length = 115\n",
      "Episode 40000 completed, episode length = 110\n",
      "Episode 41000 completed, episode length = 176\n",
      "Episode 42000 completed, episode length = 190\n",
      "Episode 43000 completed, episode length = 200\n",
      "Episode 44000 completed, episode length = 39\n",
      "Episode 45000 completed, episode length = 44\n",
      "Episode 46000 completed, episode length = 164\n",
      "Episode 47000 completed, episode length = 200\n",
      "Episode 48000 completed, episode length = 118\n",
      "Episode 49000 completed, episode length = 174\n",
      "Episode 50000 completed, episode length = 200\n",
      "Episode 51000 completed, episode length = 116\n",
      "Episode 52000 completed, episode length = 104\n",
      "Episode 53000 completed, episode length = 122\n",
      "Episode 54000 completed, episode length = 122\n",
      "Episode 55000 completed, episode length = 127\n",
      "Episode 56000 completed, episode length = 173\n",
      "Episode 57000 completed, episode length = 200\n",
      "Episode 58000 completed, episode length = 80\n",
      "Episode 59000 completed, episode length = 152\n",
      "Episode 60000 completed, episode length = 162\n",
      "Episode 61000 completed, episode length = 200\n",
      "Episode 62000 completed, episode length = 135\n",
      "Episode 63000 completed, episode length = 188\n",
      "Episode 64000 completed, episode length = 38\n",
      "Episode 65000 completed, episode length = 200\n",
      "Episode 66000 completed, episode length = 114\n",
      "Episode 67000 completed, episode length = 110\n",
      "Episode 68000 completed, episode length = 148\n",
      "Episode 69000 completed, episode length = 200\n",
      "Episode 70000 completed, episode length = 119\n",
      "Episode 71000 completed, episode length = 188\n",
      "Episode 72000 completed, episode length = 191\n",
      "Episode 73000 completed, episode length = 111\n",
      "Episode 74000 completed, episode length = 200\n",
      "Episode 75000 completed, episode length = 200\n",
      "Episode 76000 completed, episode length = 193\n",
      "Episode 77000 completed, episode length = 111\n",
      "Episode 78000 completed, episode length = 200\n",
      "Episode 79000 completed, episode length = 190\n",
      "Episode 80000 completed, episode length = 165\n",
      "Episode 81000 completed, episode length = 128\n",
      "Episode 82000 completed, episode length = 151\n",
      "Episode 83000 completed, episode length = 200\n",
      "Episode 84000 completed, episode length = 100\n",
      "Episode 85000 completed, episode length = 110\n",
      "Episode 86000 completed, episode length = 98\n",
      "Episode 87000 completed, episode length = 200\n",
      "Episode 88000 completed, episode length = 86\n",
      "Episode 89000 completed, episode length = 172\n",
      "Episode 90000 completed, episode length = 110\n",
      "Episode 91000 completed, episode length = 200\n",
      "Episode 92000 completed, episode length = 126\n",
      "Episode 93000 completed, episode length = 182\n",
      "Episode 94000 completed, episode length = 200\n",
      "Episode 95000 completed, episode length = 144\n",
      "Episode 96000 completed, episode length = 192\n",
      "Episode 97000 completed, episode length = 200\n",
      "Episode 98000 completed, episode length = 200\n",
      "Episode 99000 completed, episode length = 200\n",
      "Episode 100000 completed, episode length = 114\n",
      "Average steps balanced in test episodes: 158.3\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# --- Helper functions for discretization ---\n",
    "# Define discretization parameters:\n",
    "NUM_BINS = (6, 6, 12, 12)  # Number of bins for each of the 4 state dimensions\n",
    "\n",
    "# Define approximate bounds for each state variable:\n",
    "# [cart position, cart velocity, pole angle, pole angular velocity]\n",
    "state_bounds = [\n",
    "    (-4.8, 4.8),       # cart position\n",
    "    (-3.0, 3.0),       # cart velocity\n",
    "    (-0.418, 0.418),   # pole angle (radians ~ 24 degrees)\n",
    "    (-2.0, 2.0)        # pole angular velocity\n",
    "]\n",
    "\n",
    "def discretize_state(state):\n",
    "    \"\"\"\n",
    "    Map a continuous state (a list or numpy array) into a tuple of discrete indices.\n",
    "    \"\"\"\n",
    "    ratios = []\n",
    "    for i in range(len(state)):\n",
    "        # Clip state to within the bounds:\n",
    "        clipped = np.clip(state[i], state_bounds[i][0], state_bounds[i][1])\n",
    "        ratio = (clipped - state_bounds[i][0]) / (state_bounds[i][1] - state_bounds[i][0])\n",
    "        ratios.append(ratio)\n",
    "    new_state = tuple([int(round((NUM_BINS[i] - 1) * ratios[i])) for i in range(len(state))])\n",
    "    # Ensure indices are within [0, NUM_BINS[i]-1]\n",
    "    new_state = tuple([min(NUM_BINS[i]-1, max(0, new_state[i])) for i in range(len(state))])\n",
    "    return new_state\n",
    "\n",
    "# --- Monte Carlo Off-Policy Control Setup ---\n",
    "env = gym.make(\"CartPole-v0\")\n",
    "actions = list(range(env.action_space.n))  # CartPole has 2 actions: 0 and 1\n",
    "\n",
    "# Initialize Q(s,a), C(s,a) for weighted importance sampling, and target policy pi(s)\n",
    "Q = {}\n",
    "C = {}\n",
    "pi = {}\n",
    "\n",
    "# Initialize for each discretized state (using nested loops over bins)\n",
    "for i in range(NUM_BINS[0]):\n",
    "    for j in range(NUM_BINS[1]):\n",
    "        for k in range(NUM_BINS[2]):\n",
    "            for l in range(NUM_BINS[3]):\n",
    "                s = (i, j, k, l)\n",
    "                for a in actions:\n",
    "                    Q[(s, a)] = 0.0\n",
    "                    C[(s, a)] = 0.0\n",
    "                # Initially, set the target policy arbitrarily (here, action 0)\n",
    "                pi[s] = 0\n",
    "\n",
    "# Define behavior policy b as an epsilon-soft policy\n",
    "epsilon = 0.1\n",
    "\n",
    "def behavior_policy(state_disc):\n",
    "    \"\"\"Return an action sampled from an epsilon-soft behavior policy.\"\"\"\n",
    "    if random.random() < epsilon:\n",
    "        return random.choice(actions)\n",
    "    else:\n",
    "        # Greedy with respect to Q\n",
    "        q_values = [Q[(state_disc, a)] for a in actions]\n",
    "        max_q = max(q_values)\n",
    "        greedy_actions = [a for a, q in zip(actions, q_values) if q == max_q]\n",
    "        return random.choice(greedy_actions)\n",
    "\n",
    "def target_policy(state_disc):\n",
    "    \"\"\"Return the greedy action with respect to Q (deterministic target policy).\"\"\"\n",
    "    q_values = [Q[(state_disc, a)] for a in actions]\n",
    "    max_q = max(q_values)\n",
    "    greedy_actions = [a for a, q in zip(actions, q_values) if q == max_q]\n",
    "    return random.choice(greedy_actions)\n",
    "\n",
    "# --- MC Control using Weighted Importance Sampling (Off-Policy) ---\n",
    "num_episodes = 100000\n",
    "gamma = 0.9  # discount factor\n",
    "\n",
    "# For logging\n",
    "episode_lengths = []\n",
    "\n",
    "for episode in range(num_episodes):\n",
    "    # Generate an episode using behavior policy b\n",
    "    episode_data = []  # will store tuples: (state_disc, action, reward)\n",
    "    state, _ = env.reset()  # unpack observation and info\n",
    "    state_disc = discretize_state(state)\n",
    "    \n",
    "    done = False\n",
    "    while not done:\n",
    "        action = behavior_policy(state_disc)\n",
    "        next_state, reward, done, truncated, _ = env.step(action)\n",
    "        done = done or truncated  # combine done and truncated flags\n",
    "        next_state_disc = discretize_state(next_state)\n",
    "        episode_data.append((state_disc, action, reward))\n",
    "        state_disc = next_state_disc\n",
    "\n",
    "    episode_lengths.append(len(episode_data))\n",
    "    \n",
    "    # Calculate return G and update Q using weighted importance sampling (first-visit MC)\n",
    "    G = 0\n",
    "    W = 1.0  # cumulative importance sampling ratio\n",
    "    # Process the episode backwards:\n",
    "    for t in reversed(range(len(episode_data))):\n",
    "        s, a, r = episode_data[t]\n",
    "        G = r + gamma * G  # compute return from time t\n",
    "        \n",
    "        # Check if (s, a) first occurred at time t in this episode\n",
    "        if (s, a) not in [(x[0], x[1]) for x in episode_data[:t]]:\n",
    "            # Update C(s, a) and Q(s, a)\n",
    "            C[(s, a)] += W\n",
    "            Q[(s, a)] += (W / C[(s, a)]) * (G - Q[(s, a)])\n",
    "            # Update the target policy to be greedy with respect to Q\n",
    "            pi[s] = target_policy(s)\n",
    "            # If the action taken is not the one chosen by the target policy, stop updates for this episode\n",
    "            if a != pi[s]:\n",
    "                break\n",
    "            # Update W (importance sampling ratio)\n",
    "            # For epsilon-soft behavior, probability for greedy action is:\n",
    "            b_prob = (1 - epsilon + epsilon / len(actions)) if a == target_policy(s) else (epsilon / len(actions))\n",
    "            pi_prob = 1.0  # target policy is deterministic greedy\n",
    "            W *= (pi_prob / b_prob)\n",
    "            if W == 0:\n",
    "                break\n",
    "\n",
    "    if (episode + 1) % 1000 == 0:\n",
    "        print(f\"Episode {episode+1} completed, episode length = {len(episode_data)}\")\n",
    "\n",
    "# --- Testing the Learned Policy ---\n",
    "# Test the target policy (greedy with respect to Q)\n",
    "test_episodes = 20\n",
    "test_lengths = []\n",
    "for _ in range(test_episodes):\n",
    "    state, _ = env.reset()\n",
    "    state_disc = discretize_state(state)\n",
    "    done = False\n",
    "    steps = 0\n",
    "    while not done and steps < 10000:\n",
    "        a = target_policy(state_disc)\n",
    "        state, reward, done, truncated, _ = env.step(a)\n",
    "        done = done or truncated\n",
    "        state_disc = discretize_state(state)\n",
    "        steps += 1\n",
    "    test_lengths.append(steps)\n",
    "\n",
    "env.close()\n",
    "print(\"Average steps balanced in test episodes:\", np.mean(test_lengths))\n",
    "\n",
    "# Plotting episode lengths during training (optional)\n",
    "plt.plot(episode_lengths)\n",
    "plt.xlabel(\"Episode\")\n",
    "plt.ylabel(\"Episode Length\")\n",
    "plt.title(\"Episode Lengths over Training\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "import random\n",
    "\n",
    "# Discretization helper function\n",
    "def discretize(obs, bins):\n",
    "    upper_bounds = [4.8, 5, 0.418, 5]\n",
    "    lower_bounds = [-4.8, -5, -0.418, -5]\n",
    "    ratios = [(obs[i] + abs(lower_bounds[i])) / (upper_bounds[i] - lower_bounds[i]) for i in range(len(obs))]\n",
    "    new_obs = [int(round((bins - 1) * ratios[i])) for i in range(len(obs))]\n",
    "    new_obs = [min(bins - 1, max(0, new_obs[i])) for i in range(len(obs))]\n",
    "    return tuple(new_obs)\n",
    "\n",
    "# Dynamic Programming - Value Iteration\n",
    "def value_iteration(env, bins=10, gamma=0.99, theta=0.0001):\n",
    "    V = defaultdict(float)\n",
    "    policy = defaultdict(int)\n",
    "\n",
    "    while True:\n",
    "        delta = 0\n",
    "        for obs in np.ndindex((bins, bins, bins, bins)):\n",
    "            v = V[obs]\n",
    "            q_values = []\n",
    "            for action in [0, 1]:\n",
    "                env.reset()\n",
    "                env.env.state = [random.uniform(-0.05, 0.05) for _ in range(4)]\n",
    "                disc_obs = obs\n",
    "                env.env.state = [((o / (bins - 1)) * (ub - lb) + lb) for o, lb, ub in zip(disc_obs, [-4.8, -5, -0.418, -5], [4.8, 5, 0.418, 5])]\n",
    "                next_obs, reward, done, _ = env.step(action)\n",
    "                disc_next_obs = discretize(next_obs, bins)\n",
    "                q_values.append(reward + gamma * V[disc_next_obs])\n",
    "            V[obs] = max(q_values)\n",
    "            policy[obs] = np.argmax(q_values)\n",
    "            delta = max(delta, abs(v - V[obs]))\n",
    "        if delta < theta:\n",
    "            break\n",
    "    return policy\n",
    "\n",
    "# Monte Carlo Control with Epsilon-Greedy\n",
    "def mc_control(env, bins=10, episodes=10000, gamma=0.99, epsilon=0.1):\n",
    "    Q = defaultdict(lambda: np.zeros(env.action_space.n))\n",
    "    returns_sum = defaultdict(float)\n",
    "    returns_count = defaultdict(float)\n",
    "\n",
    "    for i in range(episodes):\n",
    "        obs = env.reset()\n",
    "        episode = []\n",
    "        done = False\n",
    "\n",
    "        while not done:\n",
    "            disc_obs = discretize(obs, bins)\n",
    "            if random.uniform(0, 1) < epsilon:\n",
    "                action = env.action_space.sample()\n",
    "            else:\n",
    "                action = np.argmax(Q[disc_obs])\n",
    "            next_obs, reward, done, _ = env.step(action)\n",
    "            episode.append((disc_obs, action, reward))\n",
    "            obs = next_obs\n",
    "\n",
    "        G = 0\n",
    "        for state, action, reward in reversed(episode):\n",
    "            G = gamma * G + reward\n",
    "            if not (state, action) in [(x[0], x[1]) for x in episode[:-1]]:\n",
    "                returns_sum[(state, action)] += G\n",
    "                returns_count[(state, action)] += 1\n",
    "                Q[state][action] = returns_sum[(state, action)] / returns_count[(state, action)]\n",
    "\n",
    "    policy = {state: np.argmax(actions) for state, actions in Q.items()}\n",
    "    return policy\n",
    "\n",
    "# Running the policies\n",
    "def run_policy(env, policy, bins=10, episodes=10):\n",
    "    for ep in range(episodes):\n",
    "        obs = env.reset()\n",
    "        total_reward = 0\n",
    "        done = False\n",
    "        while not done:\n",
    "            disc_obs = discretize(obs, bins)\n",
    "            action = policy.get(disc_obs, env.action_space.sample())\n",
    "            obs, reward, done, _ = env.step(action)\n",
    "            total_reward += reward\n",
    "            env.render()\n",
    "        print(f\"Episode {ep + 1}: Total Reward: {total_reward}\")\n",
    "    env.close()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running Dynamic Programming (Value Iteration)...\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m env \u001b[38;5;241m=\u001b[39m gym\u001b[38;5;241m.\u001b[39mmake(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCartPole-v0\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mRunning Dynamic Programming (Value Iteration)...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m dp_policy \u001b[38;5;241m=\u001b[39m \u001b[43mvalue_iteration\u001b[49m\u001b[43m(\u001b[49m\u001b[43menv\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m run_policy(env, dp_policy)\n\u001b[1;32m      6\u001b[0m env\u001b[38;5;241m.\u001b[39mclose()\n",
      "Cell \u001b[0;32mIn[1], line 31\u001b[0m, in \u001b[0;36mvalue_iteration\u001b[0;34m(env, bins, gamma, theta)\u001b[0m\n\u001b[1;32m     29\u001b[0m disc_obs \u001b[38;5;241m=\u001b[39m obs\n\u001b[1;32m     30\u001b[0m env\u001b[38;5;241m.\u001b[39menv\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m=\u001b[39m [((o \u001b[38;5;241m/\u001b[39m (bins \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m)) \u001b[38;5;241m*\u001b[39m (ub \u001b[38;5;241m-\u001b[39m lb) \u001b[38;5;241m+\u001b[39m lb) \u001b[38;5;28;01mfor\u001b[39;00m o, lb, ub \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(disc_obs, [\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m4.8\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m5\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m0.418\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m5\u001b[39m], [\u001b[38;5;241m4.8\u001b[39m, \u001b[38;5;241m5\u001b[39m, \u001b[38;5;241m0.418\u001b[39m, \u001b[38;5;241m5\u001b[39m])]\n\u001b[0;32m---> 31\u001b[0m next_obs, reward, done, _ \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mstep(action)\n\u001b[1;32m     32\u001b[0m disc_next_obs \u001b[38;5;241m=\u001b[39m discretize(next_obs, bins)\n\u001b[1;32m     33\u001b[0m q_values\u001b[38;5;241m.\u001b[39mappend(reward \u001b[38;5;241m+\u001b[39m gamma \u001b[38;5;241m*\u001b[39m V[disc_next_obs])\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 4)"
     ]
    }
   ],
   "source": [
    "env = gym.make(\"CartPole-v0\")\n",
    "\n",
    "print(\"\\nRunning Dynamic Programming (Value Iteration)...\")\n",
    "dp_policy = value_iteration(env)\n",
    "run_policy(env, dp_policy)\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nRunning Monte Carlo Control...\")\n",
    "mc_policy = mc_control(env)\n",
    "run_policy(env, mc_policy)\n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running Dynamic Programming (Value Iteration)...\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 92\u001b[0m\n\u001b[1;32m     89\u001b[0m env \u001b[38;5;241m=\u001b[39m gym\u001b[38;5;241m.\u001b[39mmake(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCartPole-v0\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     91\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mRunning Dynamic Programming (Value Iteration)...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 92\u001b[0m dp_policy \u001b[38;5;241m=\u001b[39m \u001b[43mvalue_iteration\u001b[49m\u001b[43m(\u001b[49m\u001b[43menv\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     93\u001b[0m run_policy(env, dp_policy)\n\u001b[1;32m     95\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mRunning Monte Carlo Control...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[6], line 31\u001b[0m, in \u001b[0;36mvalue_iteration\u001b[0;34m(env, bins, gamma, theta)\u001b[0m\n\u001b[1;32m     29\u001b[0m disc_obs \u001b[38;5;241m=\u001b[39m obs\n\u001b[1;32m     30\u001b[0m env\u001b[38;5;241m.\u001b[39menv\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m=\u001b[39m [((o \u001b[38;5;241m/\u001b[39m (bins \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m)) \u001b[38;5;241m*\u001b[39m (ub \u001b[38;5;241m-\u001b[39m lb) \u001b[38;5;241m+\u001b[39m lb) \u001b[38;5;28;01mfor\u001b[39;00m o, lb, ub \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(disc_obs, [\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m4.8\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m5\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m0.418\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m5\u001b[39m], [\u001b[38;5;241m4.8\u001b[39m, \u001b[38;5;241m5\u001b[39m, \u001b[38;5;241m0.418\u001b[39m, \u001b[38;5;241m5\u001b[39m])]\n\u001b[0;32m---> 31\u001b[0m next_obs, reward, done, _ \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mstep(action)\n\u001b[1;32m     32\u001b[0m disc_next_obs \u001b[38;5;241m=\u001b[39m discretize(next_obs, bins)\n\u001b[1;32m     33\u001b[0m q_values\u001b[38;5;241m.\u001b[39mappend(reward \u001b[38;5;241m+\u001b[39m gamma \u001b[38;5;241m*\u001b[39m V[disc_next_obs])\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 4)"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "import random\n",
    "\n",
    "# Discretization helper function\n",
    "def discretize(obs, bins):\n",
    "    upper_bounds = [4.8, 5, 0.418, 5]\n",
    "    lower_bounds = [-4.8, -5, -0.418, -5]\n",
    "    ratios = [(obs[i] + abs(lower_bounds[i])) / (upper_bounds[i] - lower_bounds[i]) for i in range(len(obs))]\n",
    "    new_obs = [int(round((bins - 1) * ratios[i])) for i in range(len(obs))]\n",
    "    new_obs = [min(bins - 1, max(0, new_obs[i])) for i in range(len(obs))]\n",
    "    return tuple(new_obs)\n",
    "\n",
    "# Dynamic Programming - Value Iteration\n",
    "def value_iteration(env, bins=10, gamma=0.99, theta=0.0001):\n",
    "    V = defaultdict(float)\n",
    "    policy = defaultdict(int)\n",
    "\n",
    "    while True:\n",
    "        delta = 0\n",
    "        for obs in np.ndindex((bins, bins, bins, bins)):\n",
    "            v = V[obs]\n",
    "            q_values = []\n",
    "            for action in [0, 1]:\n",
    "                env.reset()\n",
    "                env.env.state = [random.uniform(-0.05, 0.05) for _ in range(4)]\n",
    "                disc_obs = obs\n",
    "                env.env.state = [((o / (bins - 1)) * (ub - lb) + lb) for o, lb, ub in zip(disc_obs, [-4.8, -5, -0.418, -5], [4.8, 5, 0.418, 5])]\n",
    "                next_obs, reward, done, _ = env.step(action)\n",
    "                disc_next_obs = discretize(next_obs, bins)\n",
    "                q_values.append(reward + gamma * V[disc_next_obs])\n",
    "            V[obs] = max(q_values)\n",
    "            policy[obs] = np.argmax(q_values)\n",
    "            delta = max(delta, abs(v - V[obs]))\n",
    "        if delta < theta:\n",
    "            break\n",
    "    return policy\n",
    "\n",
    "# Monte Carlo Control with Epsilon-Greedy\n",
    "def mc_control(env, bins=10, episodes=10000, gamma=0.99, epsilon=0.1):\n",
    "    Q = defaultdict(lambda: np.zeros(env.action_space.n))\n",
    "    returns_sum = defaultdict(float)\n",
    "    returns_count = defaultdict(float)\n",
    "\n",
    "    for i in range(episodes):\n",
    "        obs = env.reset()\n",
    "        episode = []\n",
    "        done = False\n",
    "\n",
    "        while not done:\n",
    "            disc_obs = discretize(obs, bins)\n",
    "            if random.uniform(0, 1) < epsilon:\n",
    "                action = env.action_space.sample()\n",
    "            else:\n",
    "                action = np.argmax(Q[disc_obs])\n",
    "            next_obs, reward, done, _ = env.step(action)\n",
    "            episode.append((disc_obs, action, reward))\n",
    "            obs = next_obs\n",
    "\n",
    "        G = 0\n",
    "        for state, action, reward in reversed(episode):\n",
    "            G = gamma * G + reward\n",
    "            if not (state, action) in [(x[0], x[1]) for x in episode[:-1]]:\n",
    "                returns_sum[(state, action)] += G\n",
    "                returns_count[(state, action)] += 1\n",
    "                Q[state][action] = returns_sum[(state, action)] / returns_count[(state, action)]\n",
    "\n",
    "    policy = {state: np.argmax(actions) for state, actions in Q.items()}\n",
    "    return policy\n",
    "\n",
    "# Running the policies\n",
    "def run_policy(env, policy, bins=10, episodes=10):\n",
    "    for ep in range(episodes):\n",
    "        obs = env.reset()\n",
    "        total_reward = 0\n",
    "        done = False\n",
    "        while not done:\n",
    "            disc_obs = discretize(obs, bins)\n",
    "            action = policy.get(disc_obs, env.action_space.sample())\n",
    "            obs, reward, done, _ = env.step(action)\n",
    "            total_reward += reward\n",
    "            env.render()\n",
    "        print(f\"Episode {ep + 1}: Total Reward: {total_reward}\")\n",
    "    env.close()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    env = gym.make(\"CartPole-v0\")\n",
    "\n",
    "    print(\"\\nRunning Dynamic Programming (Value Iteration)...\")\n",
    "    dp_policy = value_iteration(env)\n",
    "    run_policy(env, dp_policy)\n",
    "\n",
    "    print(\"\\nRunning Monte Carlo Control...\")\n",
    "    mc_policy = mc_control(env)\n",
    "    run_policy(env, mc_policy)\n",
    "\n",
    "    env.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mygym",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
